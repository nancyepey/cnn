{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d0d775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "# bring in the data and make some processing with the data\n",
    "TEST_DIR = \"C:/Users/Nancy/Documents/school/cnn/data/test\"\n",
    "TRAIN_DIR = \"C:/Users/Nancy/Documents/school/cnn/data/train\"\n",
    "IMG_SIZE = 50 #resize the image to 50 by 50\n",
    "LR = 1e-3 #learning rate is 0.001\n",
    "\n",
    "# \n",
    "MODEL_NAME = 'skinColor-{}-{}.model'.format(LR, '2conv-basic-video')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b214b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the label of the image\n",
    "def label_img(img):\n",
    "    word_label = img.split('.')[0][:3]\n",
    "    # with 5 people\n",
    "    if   word_label == 'nan': return [1,0,0,0,0,0]\n",
    "    elif word_label == 'emi': return [0,1,0,0,0,0]\n",
    "    elif word_label == 'fel': return [0,0,1,0,0,0]\n",
    "    elif word_label == 'ken': return [0,0,0,1,0,0]\n",
    "    elif word_label == 'mar': return [0,0,0,0,1,0]\n",
    "    elif word_label == 'mam': return [0,0,0,0,0,1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a033ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper fxn\n",
    "# create train data, labeled images\n",
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR, img)\n",
    "        img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE))\n",
    "        training_data.append([np.array(img), np.array(label)])\n",
    "\n",
    "    # shuffle the data\n",
    "    shuffle(training_data)\n",
    "    # save the training data numpy array\n",
    "    # np.save('train_dataNew.npy', training_data)\n",
    "    # return the traininng data\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab1a4c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# competition text data with no label\n",
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR, img)\n",
    "        img_num = img.split('.')[0] # getting the img\n",
    "        #resizing the image\n",
    "        img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "    \n",
    "    shuffle(testing_data)\n",
    "    # save data\n",
    "    # np.save('test_dataNew.npy', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5690d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8512/8512 [03:32<00:00, 40.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# first run\n",
    "train_data = create_train_data()\n",
    "# if you already have train data\n",
    "#train_data = np.load('train_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fa5cf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nancy\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\Nancy\\anaconda3\\lib\\site-packages\\tflearn\\initializations.py:110: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Nancy\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:561: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From C:\\Users\\Nancy\\anaconda3\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Nancy\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# using tflearn\n",
    "#cnn\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "# convnet = fully_connected(convnet, 1, activation='softmax')\n",
    "\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c892d837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train data: 8512\n",
      "Train data 8012\n",
      "Test data 500\n"
     ]
    }
   ],
   "source": [
    "# All are labeled data\n",
    "# separate the training and testing data for the accuracy of our models\n",
    "train = train_data[:-500] # the train data is the last 500 sample data\n",
    "test = train_data[-500:]\n",
    "print(\"Total train data: \"+str(len(train_data)))\n",
    "print(\"Train data \" + str(len(train)))\n",
    "print(\"Test data \"+ str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b29baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data getting fit\n",
    "# the zero element was the image data, the pixel data\n",
    "X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 2) # featured set\n",
    "Y = [i[1] for i in train] # Labels\n",
    "\n",
    "# For testing accurancy\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 2) # featured set\n",
    "test_y = [i[1] for i in test] # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b02ae070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: skinColor-0.001-2conv-basic-video.model\n",
      "Log directory: log/\n",
      "---------------------------------\n",
      "Training samples: 8012\n",
      "Validation samples: 250\n",
      "--\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (64, 6) for Tensor targets/Y:0, which has shape (?, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13020/1113962613.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msnapshot_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tflearn\\models\\dnn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;31m# Retrieve data preprocesing and augmentation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mdaug_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdprep_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve_data_preprocessing_and_augmentation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         self.trainer.fit(feed_dicts, val_feed_dicts=val_feed_dicts,\n\u001b[0m\u001b[0;32m    197\u001b[0m                          \u001b[0mn_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                          \u001b[0mshow_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_metric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, feed_dicts, n_epoch, val_feed_dicts, show_metric, snapshot_step, snapshot_epoch, shuffle_all, dprep_dict, daug_dict, excl_trainops, run_id, callbacks)\u001b[0m\n\u001b[0;32m    339\u001b[0m                             \u001b[0mcaller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_sub_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                             snapshot = train_op._train(self.training_state.step,\n\u001b[0m\u001b[0;32m    342\u001b[0m                                                        \u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0msnapshot_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m                                                        \u001b[0msnapshot_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, training_step, snapshot_epoch, snapshot_step, show_metric)\u001b[0m\n\u001b[0;32m    825\u001b[0m         \u001b[0mfeed_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m         \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 827\u001b[1;33m         _, train_summ_str = self.session.run([self.train, self.summ_op],\n\u001b[0m\u001b[0;32m    828\u001b[0m                                              feed_batch)\n\u001b[0;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1162\u001b[0m           if (not is_tensor_handle_feed and\n\u001b[0;32m   1163\u001b[0m               not subfeed_t.get_shape().is_compatible_with(np_val.shape)):\n\u001b[1;32m-> 1164\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1165\u001b[0m                 \u001b[1;34mf'Cannot feed value of shape {str(np_val.shape)} for Tensor '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m                 \u001b[1;34mf'{subfeed_t.name}, which has shape '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (64, 6) for Tensor targets/Y:0, which has shape (?, 2)"
     ]
    }
   ],
   "source": [
    "# reshape X and Y\n",
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = np.array([i[1] for i in train]).reshape(-1,1)\n",
    "# Y = Y.reshape(len(Y), -1)\n",
    "Y = Y.reshape(len(Y), 1)\n",
    "Y = [i[1] for i in train] # Labels\n",
    "\n",
    "# Train the network\n",
    "# model.fit({'input': X}, {'targets': Y}, n_epoch=6, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "#     snapshot_step=500, show_metric=True, run_id=MODEL_NAME) #run id is how we will find it in tensorboard\n",
    "\n",
    "# model.fit( X, Y, n_epoch=5,\n",
    "# validation_set=(test_x,test_y),\n",
    "# snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n",
    "\n",
    "model.fit(X,Y, n_epoch=10, validation_set=(test_x,test_y), snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248362be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3857100d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4360f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
